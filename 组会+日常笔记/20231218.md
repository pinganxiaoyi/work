# 20231218

---

## DGL

### 过拟合

  观察过拟合是机器学习和深度学习中的一个常见问题，它发生在模型过度学习训练数据的特定细节和噪声，而未能从中提取出泛化到未见数据的一般性模式。你可以通过比较训练精度和测试精度来判断模型是否出现过拟合。

#### 如何通过训练精度和测试精度识别过拟合

1. **高训练精度，低测试精度**：这是过拟合的经典迹象。如果模型在训练数据上表现得非常好（高训练精度），但在未见过的测试数据上表现较差（低测试精度），则很可能是模型学到了训练数据中的噪声和非泛化特征。

2. **训练精度持续提升，测试精度开始下降**：在训练过程中，如果观察到训练精度随着时间不断提高，而测试精度在达到某个点后开始下降，这通常意味着过拟合。模型开始学习训练数据中的特定模式，而这些模式对于新数据并不适用。

#### 解决过拟合的策略

1. **数据增强**：通过增加训练数据的多样性来提高模型的泛化能力。
2. **正则化**：使用L1或L2正则化可以惩罚过大的模型权重，从而防止过拟合。
3. **减少模型复杂度**：减小网络的大小，减少层数或神经元的数量，使模型的容量与数据的复杂性相匹配。
4. **早停（Early Stopping）**：当测试精度不再提高时停止训练。
5. **使用Dropout**：在训练过程中随机丢弃神经元，可以增强模型的泛化能力。
6. **交叉验证**：使用交叉验证可以更好地评估模型的泛化能力。

#### 结论

通过监控训练和测试精度，可以有效地识别过拟合。如果测试精度明显低于训练精度，或者测试精度在一段时间后开始下降，这可能是过拟合的迹象。在这种情况下，应当采取适当的策略来改善模型的泛化能力。

- [ ] 看不同文件的trackID==3的数目